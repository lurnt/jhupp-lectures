{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark: Cloud Programming with Memory\n",
    "\n",
    "Lecture derived from: Zaharia et al. Resilient distributed datasets: a fault-tolerant abstraction for in-memory cluster computing. USENIX NSDI, 2012.\n",
    "\n",
    "* Map/Reduce style programming\n",
    "  * Data-parallel, batch, restrictive model, functional\n",
    "  * Abstractions to leverage distributed memory\n",
    "* New interfaces to in-memory computations\n",
    "  * Fault-tolerant\n",
    "  * Lazy materialization (pipelined evaluation)\n",
    "* Good support for iterative computations on in-memory data sets leads to good performance\n",
    "  * 20x over Map/Reduce\n",
    "  * No writing data to file system, loading data from file system, during iteration\n",
    "  \n",
    "#### RDD: Resilient Distributed Dataset\n",
    "\n",
    "This is the central abstraction of Spark.\n",
    "* Read-only partitioned collection of records\n",
    "* Created from:\n",
    "  * Data in stable storage\n",
    "  * Transformations on other RDDs\n",
    "* Unit of parallelism in a data decomposition:\n",
    "  * Automatic parallelization of transformation, such as map, reduce, filter, etc.\n",
    "* RDDs are not data:\n",
    "  * Not materialized.  They are an abstraction.\n",
    "  * Defined by lineage. Set of transformations on a original data set.\n",
    "  \n",
    "  \n",
    "```scala\n",
    "lines = spark.textFile(\"hdfs://...\")\n",
    "errors = lines.filter(_.startsWith(\"ERROR\"))\n",
    "errors.pes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
